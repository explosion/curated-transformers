[metadata]
version = 0.0.6
description = Curated transformer models
url = https://github.com/explosion/curated-transformers
author = Explosion
author_email = contact@explosion.ai
license = MIT
license_file = LICENSE
long_description = file: README.md
long_description_content_type = text/markdown

[options]
zip_safe = true
include_package_data = true
python_requires = >=3.6
install_requires =
    cutlery>=0.0.3,<0.1.0
    spacy>=3.5.0,<4.0.0
    torch>=1.12.0

[options.entry_points]
spacy_factories =
    curated_transformer = curated_transformers.pipeline.transformer:make_transformer

spacy_architectures =
    curated-transformers.AlbertTransformer.v1 = curated_transformers.models:build_albert_transformer_model_v1
    curated-transformers.BertTransformer.v1 = curated_transformers.models:build_bert_transformer_model_v1
    curated-transformers.CamembertTransformer.v1 = curated_transformers.models:build_camembert_transformer_model_v1
    curated-transformers.RobertaTransformer.v1 = curated_transformers.models:build_roberta_transformer_model_v1
    curated-transformers.XlmrTransformer.v1 = curated_transformers.models:build_xlmr_transformer_model_v1
    curated-transformers.WithStridedSpans.v1 = curated_transformers.models:build_with_strided_spans_v1
    curated-transformers.ScalarWeight.v1 = curated_transformers.models:build_scalar_weight_v1
    curated-transformers.TransformerLayersListener.v1 = curated_transformers.models.listeners:build_transformer_layers_listener_v1
    curated-transformers.LastTransformerLayerListener.v1 = curated_transformers.models.listeners:build_last_transformer_layer_listener_v1
    curated-transformers.ScalarWeightingListener.v1 = curated_transformers.models.listeners:build_scalar_weighting_listener_v1
    curated-transformers.BertWordpieceEncoder.v1 = curated_transformers.tokenization:build_bert_wordpiece_encoder_v1
    curated-transformers.ByteBPEEncoder.v1 = curated_transformers.tokenization:build_byte_bpe_encoder_v1
    curated-transformers.CamembertSentencepieceEncoder.v1 = curated_transformers.tokenization:build_camembert_sentencepiece_encoder_v1
    curated-transformers.CharEncoder.v1 = curated_transformers.tokenization:build_char_encoder_v1
    curated-transformers.SentencepieceEncoder.v1 = curated_transformers.tokenization:build_sentencepiece_encoder_v1
    curated-transformers.WordpieceEncoder.v1 = curated_transformers.tokenization:build_wordpiece_encoder_v1
    curated-transformers.XlmrSentencepieceEncoder.v1 = curated_transformers.tokenization:build_xlmr_sentencepiece_encoder_v1

spacy_callbacks =
    curated-transformers.gradual_transformer_unfreezing.v1 = curated_transformers.util:create_gradual_transformer_unfreezing

spacy_cli =
    curated-transformers.debug_pieces = curated_transformers.cli.debug_pieces:debug_pieces_cli
    curated-transformers.quantize = curated_transformers.cli.quantize:quantize_cli

thinc_model_loaders =
    curated-transformers.ByteBPELoader.v1 = curated_transformers.tokenization:build_byte_bpe_encoder_loader_v1
    curated-transformers.CharEncoderLoader.v1 = curated_transformers.tokenization:build_char_encoder_loader_v1
    curated-transformers.HFTransformerEncoderLoader.v1 = curated_transformers.models:build_hf_transformer_encoder_loader_v1
    curated-transformers.HFPieceEncoderLoader.v1 = curated_transformers.tokenization:build_hf_piece_encoder_loader_v1
    curated-transformers.PyTorchCheckpointLoader.v1 = curated_transformers.models:build_pytorch_checkpoint_loader_v1
    curated-transformers.SentencepieceLoader.v1 = curated_transformers.tokenization:build_sentencepiece_encoder_loader_v1
    curated-transformers.WordpieceLoader.v1 = curated_transformers.tokenization:build_wordpiece_encoder_loader_v1

[bdist_wheel]
universal = true

[sdist]
formats = gztar

[mypy]
exclude = tests
ignore_missing_imports = True
no_implicit_optional = True
plugins = pydantic.mypy, thinc.mypy
